{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2e7925-9874-4f78-a5df-f775e15a1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кеша поет песенки\n",
      "Кеша танцует\n"
     ]
    }
   ],
   "source": [
    "# Создаем метод\n",
    "class Parrot:\n",
    "    \n",
    "    # атрибуты экземпляра\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "    \n",
    "    # метод экземпляра\n",
    "    def sing(self, song):\n",
    "        return \"{} поет {}\".format(self.name, song)\n",
    "\n",
    "    def dance(self):\n",
    "        return \"{} танцует\".format(self.name)\n",
    "\n",
    "# создаем экземпляр класса\n",
    "kesha = Parrot(\"Кеша\", 10)\n",
    "\n",
    "# вызываем методы экземпляра\n",
    "print(kesha.sing(\"песенки\"))\n",
    "print(kesha.dance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab48dce-5341-48fe-837e-26e4cd38ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Птица готова\n",
      "Пингвин готов\n",
      "Пингвин\n",
      "Плывет быстрее\n",
      "Бежит быстрее\n"
     ]
    }
   ],
   "source": [
    "class Bird:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Птица готова\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Птица\")\n",
    "\n",
    "    def swim(self):\n",
    "        print(\"Плывет быстрее\")\n",
    "\n",
    "# дочерний класс\n",
    "class Penguin(Bird):\n",
    "\n",
    "    def __init__(self):\n",
    "        # вызов функции super() \n",
    "        super().__init__()\n",
    "        print(\"Пингвин готов\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Пингвин\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Бежит быстрее\")\n",
    "\n",
    "peggy = Penguin()\n",
    "peggy.whoisThis()\n",
    "peggy.swim()\n",
    "peggy.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34877b32-867e-4225-8244-e1e41d3cef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Цена продажи: 900\n",
      "Цена продажи: 900\n",
      "Цена продажи: 1000\n"
     ]
    }
   ],
   "source": [
    "class Computer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__maxprice = 900\n",
    "\n",
    "    def sell(self):\n",
    "        print(\"Цена продажи: {}\".format(self.__maxprice))\n",
    "\n",
    "    def setMaxPrice(self, price):\n",
    "        self.__maxprice = price\n",
    "\n",
    "c = Computer()\n",
    "c.sell()\n",
    "\n",
    "# изменение цены\n",
    "c.__maxprice = 1000\n",
    "c.sell()\n",
    "\n",
    "# используем функцию изменения цены\n",
    "c.setMaxPrice(1000)\n",
    "c.sell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2945b467-3405-4146-95d4-9c0df335db31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flying_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m peggy \u001b[38;5;241m=\u001b[39m Penguin()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# передача объектов в качестве аргумента\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m flying_test(kesha)\n\u001b[1;32m     28\u001b[0m flying_test(peggy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flying_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Используем полиморфизм\n",
    "class Parrot:\n",
    "\n",
    "    def fly(self):\n",
    "        print(\"Попугай умеет летать\")\n",
    "    \n",
    "    def swim(self):\n",
    "        print(\"Попугай не умеет плавать\")\n",
    "\n",
    "class Penguin:\n",
    "\n",
    "    def fly(self):\n",
    "        print(\"Пингвин не умеет летать\")\n",
    "    \n",
    "    def swim(self):\n",
    "        print(\"Пингвин умеет плавать\")\n",
    "\n",
    "# общий интерфейс \n",
    "#def flying_test(bird):\n",
    "#    bird.fly()\n",
    "\n",
    "# создаем экземпляров класса\n",
    "kesha = Parrot()\n",
    "peggy = Penguin()\n",
    "\n",
    "# передача объектов в качестве аргумента\n",
    "flying_test(kesha)\n",
    "flying_test(peggy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888cb53-ca6d-4b79-9d91-5f89ae8bc9d8",
   "metadata": {},
   "source": [
    "## Переписываем скрипт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bdbfab-b914-427a-8c2f-5c97c924c38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b5db19-d597-4479-9217-803b9b395280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAM():\n",
    "    def __init__(self, names, refs, start, cigar, read):\n",
    "        self.names = names\n",
    "        self.refs = refs\n",
    "        self.start = start\n",
    "        self.cigar = cigar\n",
    "        self.read = read       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8282151b-65bd-41ea-8865-63958fd759c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Ref(Ref_name):\n",
    "    with open('All_refs.fasta', 'r') as refs:\n",
    "        line = refs.readline()\n",
    "        ref_all = []\n",
    "        while line:\n",
    "            if Ref_name in line:# Если название референса из атрибутов совпадает с названием строки в фаста файле с референсами, следующую строку записываем как референс\n",
    "                line = refs.readline()\n",
    "                while not line.startswith(\">\"):\n",
    "                    ref = list(line)[:-1]\n",
    "                    ref_all = ref_all + ref\n",
    "                    line = refs.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "            line = refs.readline()  \n",
    "    return ref_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd36c1d-7ffb-4e79-9668-468921469f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class READ:\n",
    "    '''Объект - рид из sam-файла. \n",
    "       Атрибуты: Имя рида, имя референса, старт, сторка сигар, сам рид\n",
    "       Методы: Получить рид как он есть при выравнивании'''\n",
    "    def __init__(self, name, start, CIGAR, read): # задаем объект, где как атрибуты будут имя рида, флаг и тд\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.CIGAR = CIGAR\n",
    "        self.read = read\n",
    "    \n",
    "    def ReadySeq(self): # Получаем рид как он будет при выравнивании.\n",
    "        '''For input the self object, for output the seq is ready for comparing with reference'''\n",
    "        cigar = list(self.CIGAR.strip()) #сделали список\n",
    "        # для начала нужно сигар разбить на блоки и переделать цифры в инт. По идее олжно получиться int(61) str(S) int(37) str(M)...\n",
    "        # Каждый символ пытаюсь перевести в инт, обработка исключений на буквы\n",
    "        for i in range(len(cigar)): #пробуем каждый символ списка сделать интом\n",
    "            try:\n",
    "                cigar[i] = int(cigar[i])\n",
    "            except ValueError:\n",
    "                cigar[i] = cigar[i]\n",
    "                # чтобы не использовать исключения, можно юзать ord chr, обращаясь к символам в кодировке, по времени может быть быстрее\n",
    "\n",
    "        # Потом объединяю цифры в одно число.\n",
    "        cigar_new = []\n",
    "        for i in range(len(cigar)): # если символ - строка - записываем его отдельно\n",
    "            if type(cigar[i]) == str:\n",
    "                cigar_new.append(cigar[i])                                    \n",
    "            try:\n",
    "                if type(cigar[i]) == type(cigar[i+1]) == type(cigar[i+2]) : # если три символа подряд это инт, объединяем их\n",
    "                    cigar_new.append(int(str(cigar[i])+str(cigar[i+1])+str(cigar[i+2])))\n",
    "                if type(cigar[i]) == type(cigar[i+1]) and type(cigar[i]) != type(cigar[i+2]) and type(cigar[i-1]) ==str:  # если два символа подряд одного типа (такое может быть только с инт), объединяем их  \n",
    "                    cigar_new.append(int(str(cigar[i])+str(cigar[i+1])))\n",
    "                if type(cigar[i+1]) == str and type(cigar[i-1]) == str: # если один инт - тоже записываем его\n",
    "                    cigar_new.append(cigar[i])\n",
    "            except IndexError: # это нужно на случай окончания строки, list index out of range\n",
    "                continue\n",
    "                \n",
    "        # удобнее сделать словарь\n",
    "        numbers = cigar_new[::2] # список с числом нуклеотидов\n",
    "        clipping_type = [] # список с типом совпадений\n",
    "        \n",
    "        for i in range(1, len(cigar_new), 2): \n",
    "            clipping_type.append(cigar_new[i]);\n",
    "\n",
    "        cigar_dict = [] # делаем словарь\n",
    "        for i in range(len(numbers)):\n",
    "            cigar_dict.append((numbers[i],clipping_type[i]))\n",
    "            \n",
    "        # Теперь прогоняем сам seq по строке cigar, для каждой буквы свое действие\n",
    "        nucl_number = 0 # сразу столбец из data\n",
    "        seq = self.read\n",
    "        for e in cigar_dict:\n",
    "            if e[1] == 'S':\n",
    "                seq = seq[:nucl_number] + 'N' * e[0] + seq[nucl_number + e[0]:]\n",
    "            if e[1] == 'D':\n",
    "                seq = seq[:nucl_number] + ' ' * e[0] + seq[nucl_number:]\n",
    "            if e[1] == 'H':\n",
    "                continue # это пока, может быть hard clipping не вырезается\n",
    "            if e[1] == 'I':\n",
    "                seq = seq[:nucl_number] + 'N' * e[0] + seq[nucl_number + e[0]:]\n",
    "            nucl_number += e[0]\n",
    "        seq = seq.replace('N', '') \n",
    "        new_seq = (self.start-1) * ' ' + seq #Тут может быть ошибка, мб не надо -1\n",
    "\n",
    "        return new_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b7aacb-78d2-4275-8fbb-68526aa27360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ALIGN():\n",
    "    '''Объект -  отдельное выравнивание.\n",
    "    Атрибуты: референс по буквам, набор выровненных ридов, имена ридов, строки сигар для ридов'''\n",
    "    def __init__(self, ref, reads, reads_names, reads_cigar):\n",
    "        self.ref = ref\n",
    "        self.reads = reads\n",
    "        self.reads_names = reads_names\n",
    "        self.reads_cigar = reads_cigar\n",
    "        \n",
    "    # Функция анализа покрытия выравнивания\n",
    "    def RefCover(self):\n",
    "        '''Делает словарь покрытий по конкретному референсу и сборке.\n",
    "        На вход: Референс по буквам и Список ридов, \n",
    "        на выходе кортеж (список словарей с покрытием в процнтах для каждого нуклеотида в референсе, абсолютное покрытие этого нуклеотида)'''\n",
    "        \n",
    "        #Создаем список словарей, по длине референса, для каждого элемента 4 варианта нуклеотидов\n",
    "        abs_cover_for_all_nucl = [] # большой словарь для всех нуклеотидов, по всей длине референса, абсолютные значения\n",
    "        percent_cover_for_all_nucl = [] # большой словарь для всех нуклеотидов, по всей длине референса, процентные значения\n",
    "        for i in range(len(self.ref) + 1):\n",
    "            abs_cover_dict = {} # для каждого нуклеотида\n",
    "            abs_cover_dict['A'] = 0\n",
    "            abs_cover_dict['C'] = 0\n",
    "            abs_cover_dict['G'] = 0\n",
    "            abs_cover_dict['T']= 0\n",
    "            abs_cover_for_all_nucl.append(abs_cover_dict)\n",
    "            per_cover_dict = {} # для каждого нуклеотида\n",
    "            per_cover_dict['A'] = 0\n",
    "            per_cover_dict['C'] = 0\n",
    "            per_cover_dict['G'] = 0\n",
    "            per_cover_dict['T'] = 0\n",
    "            percent_cover_for_all_nucl.append(per_cover_dict)\n",
    "            \n",
    "        # abs_cover_for_all_nucl - абсолютное покртыие в нуклеотидах\n",
    "        # percent_cover_for_all_nucl - процентное покрытие в нуклеотидах\n",
    "\n",
    "        # заполняем типами нуклеотидов, в абсолютных значениях\n",
    "        for read in self.reads:\n",
    "            for nucl_number, nucl in enumerate(read):\n",
    "                #print(nucl, nucl_number)\n",
    "                if nucl == 'A':\n",
    "                    abs_cover_for_all_nucl[nucl_number]['A']  += 1\n",
    "                if nucl == 'T':\n",
    "                    abs_cover_for_all_nucl[nucl_number]['T']  += 1\n",
    "                if nucl == 'G':\n",
    "                    abs_cover_for_all_nucl[nucl_number]['G']  += 1\n",
    "                if nucl == 'C':\n",
    "                    abs_cover_for_all_nucl[nucl_number]['C']  += 1\n",
    "\n",
    "        cover_abs = [] #абсолютное покрытие референса, без учета типа нуклеотида\n",
    "        for nucl_number, nucl in enumerate(abs_cover_for_all_nucl): #проходимся по номеру элемента(нуклеотиду), и его значениям(словарю с типом и количеством)\n",
    "            cover = 0 # общее покрытие определенного нуклеотида\n",
    "            for key, value in nucl.items(): #Раскрываем  словарь, тип нуклеотидиа и количество \n",
    "                cover += value\n",
    "            # посчитали общее абсолютное покрытие нуклеотида - cover\n",
    "            # Далее заполняем процент различных типов, для каждой позиции в референсе\n",
    "            for key, value in nucl.items():    \n",
    "                if key == 'A':\n",
    "                    if cover == 0:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  0\n",
    "                    else:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  value * 100 / cover\n",
    "                if key == 'T':\n",
    "                    if cover == 0:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  0\n",
    "                    else:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  value * 100 / cover\n",
    "                if key == 'G':\n",
    "                    if cover == 0:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  0\n",
    "                    else:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  value * 100 / cover\n",
    "                if key == 'C':\n",
    "                    if cover == 0:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  0\n",
    "                    else:\n",
    "                        percent_cover_for_all_nucl[nucl_number][key] =  value * 100 / cover\n",
    "            cover_abs.append(cover)    \n",
    "        return percent_cover_for_all_nucl, cover_abs\n",
    "    \n",
    "    # Функция с описанием замен сборки (выравнивания)\n",
    "    def AllChanges(self):\n",
    "        '''Смотрим на все существующие замены в этой сборке для этой хромосомы.\n",
    "            На вход берем референс и риды сборки. На выходе получаем список списков, для каждого рида свой список.\n",
    "            Внутри два элемента, номер рида и номер нуклеотида с типом замены'''\n",
    "        changing = []\n",
    "        for nucl_number, nucl in enumerate(self.ref): # для всех нуклеотидов референса\n",
    "            for seq_number, seq in enumerate(self.reads): # для каждого рида сборки\n",
    "                #print(seq[nucl_number])\n",
    "                try:\n",
    "                    if seq[nucl_number] != ' ': # если нуклеотид рида существует в этой позиции\n",
    "                        if nucl != seq[nucl_number]: # если нуклеотид референса не равен нуклеотиду рида\n",
    "                            changing.append([self.reads_names[seq_number], \n",
    "                                             '{0:s}'.format(seq[nucl_number], nucl_number +1), len(seq.replace(' ', ''))])                 \n",
    "                except IndexError:\n",
    "                    continue\n",
    "        return changing\n",
    "\n",
    "    def ReadWithChanges(self, AllChanges):\n",
    "        '''Считаем количество ридов с заменами и считаем число замен в риде.\n",
    "            На вход подаем список списков из функции AllChanges.\n",
    "            На выход список кортежей с номером рида и числом замен в этом риде'''\n",
    "        read_with_change = [] # Риды с заменами\n",
    "        for e in AllChanges: # Для каждого элемента из общего файла существующих замен:\n",
    "            read_with_change.append(e[0]) # Добавляем сюда номер рида\n",
    "\n",
    "        change = [] \n",
    "        for read in read_with_change:\n",
    "            change.append(('{0:s}'.format(read), read_with_change.count(read))) # Считаем сколько раз этот рид встретился в наборе всех замен\n",
    "        read_with_change = list(set(change)) # Берем сет от этого набора:\n",
    "        return read_with_change\n",
    "    \n",
    "    \n",
    "    def Cleaning(self, ReadWithChanges, AllChanges, RefCover):\n",
    "        candidate_for_remove = [] # список кандидатов на удаление\n",
    "        for read_tuple in ReadWithChanges: # для всех ридов с заменами:\n",
    "            for i in range(len(AllChanges)): # пройдемся по списку замен\n",
    "                if read_tuple[0] == AllChanges[i][0]: # если рид с заменой в списке всех изменений, берем его длину\n",
    "                    if read_tuple[1]*100/AllChanges[i][-1] >= 10: # Более скольки процентов ридов\n",
    "                        candidate_for_remove.append(read_tuple)\n",
    "\n",
    "        count =[]\n",
    "        for read_number, read in enumerate(candidate_for_remove): # в каждом риде с большим числом замен\n",
    "            k = 0 # Счетчик редких замен\n",
    "            for i, e in enumerate(AllChanges): # иду по списку всех возможных замен\n",
    "                if read[0] == e[0]: # если совпадает название рида с ошибкой и название кандидата на удаление\n",
    "                    for cover_i, cover in enumerate(RefCover[0]): # смотрим словарь покрытия\n",
    "                        for key, value in cover.items(): # key - тип нуклеотида с заменой и его номер, value - процент покрытия для этого типа замены\n",
    "                            if key == e[1]: # когда нуклеотид совпадает с нуклеотидом из списка замен\n",
    "                                if value * RefCover[1][cover_i] / max(RefCover[1]) < 40: # для скольки процентов ридов характнрна такая замена\n",
    "                                    #print('Процент замен в риде, относительно его длины:', read[1],'\\n', 'Информация о риде и замене:',e, '\\n','Процент такой замены в целом:',value)\n",
    "                                    k+=1\n",
    "            if k !=0:\n",
    "                count.append((read,k)) # сколько в риде всего замен, и сколько из них \"Редкие\"\n",
    "        reads_for_remove = []\n",
    "        for i in count:\n",
    "            if i[1] / i[0][1] > 0.4: #если относительно всех замен рида более 40% из них редкие,\n",
    "                reads_for_remove.append(i[0][0])\n",
    "                \n",
    "        # добавить еще риды с инсерцией и делецией, если в риде более 10 процентов от длины пропущено/добавлено\n",
    "        #for i in range(len(self.reads_names)):\n",
    "        #    if self.reads_cigar[i].count('I') >= 5 or self.reads_cigar[i].count('D') >= 5:\n",
    "         #       reads_for_remove.append(self.reads_names[i])\n",
    "            \n",
    "\n",
    "        return reads_for_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7969c8-eaa2-4f28-8133-0b0c569ce27d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Идет обработка файла:  cart_Non_adapters_IonXpress_010_rawlib.basecaller.fastq.sam\n",
      "Всего референсов: 707\n",
      "Очистка сборки на референс:  UCE776_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1288\n",
      "Очистка сборки на референс:  UCE122_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 288\n",
      "Очистка сборки на референс:  UCE332_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 908\n",
      "Очистка сборки на референс:  UCE21_Claster_1_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 26\n",
      "Очистка сборки на референс:  UCE855_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 735\n",
      "Очистка сборки на референс:  UCE26_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1490\n",
      "Очистка сборки на референс:  UCE1324_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1478\n",
      "Очистка сборки на референс:  UCE1266_Claster_0_Contig3\n",
      "Число плохих ридов 0 , Число хороших ридов 1238\n",
      "Очистка сборки на референс:  UCE693_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 947\n",
      "Очистка сборки на референс:  UCE921_Claster_0_Contig1\n",
      "Число плохих ридов 68 , Число хороших ридов 682\n",
      "Очистка сборки на референс:  UCE1270_Claster_2_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 262\n",
      "Очистка сборки на референс:  UCE671_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 315\n",
      "Очистка сборки на референс:  UCE860_Claster_0_Contig1\n",
      "Число плохих ридов 51 , Число хороших ридов 595\n",
      "Очистка сборки на референс:  UCE864_Claster_0_Contig1\n",
      "Число плохих ридов 24 , Число хороших ридов 1409\n",
      "Очистка сборки на референс:  UCE948_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1752\n",
      "Очистка сборки на референс:  UCE504_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 9\n",
      "Очистка сборки на референс:  UCE691_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 61\n",
      "Очистка сборки на референс:  UCE456_Claster_0_Contig1\n",
      "Число плохих ридов 27 , Число хороших ридов 200\n",
      "Очистка сборки на референс:  UCE461_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 201\n",
      "Очистка сборки на референс:  UCE604_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 375\n",
      "Очистка сборки на референс:  UCE568_Claster_0_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 244\n",
      "Очистка сборки на референс:  UCE368_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1015\n",
      "Очистка сборки на референс:  UCE358_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1102\n",
      "Очистка сборки на референс:  UCE556_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 40\n",
      "Очистка сборки на референс:  UCE203_Claster_0_Contig1\n",
      "Число плохих ридов 152 , Число хороших ридов 3115\n",
      "Очистка сборки на референс:  UCE267_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 944\n",
      "Очистка сборки на референс:  UCE815_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 129\n",
      "Очистка сборки на референс:  UCE420_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1268\n",
      "Очистка сборки на референс:  UCE690_Claster_0_Contig1\n",
      "Число плохих ридов 82 , Число хороших ридов 1757\n",
      "Очистка сборки на референс:  UCE885_Claster_0_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 771\n",
      "Очистка сборки на референс:  UCE651_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 626\n",
      "Очистка сборки на референс:  UCE204_Claster_1_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 343\n",
      "Очистка сборки на референс:  UCE1046_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1050\n",
      "Очистка сборки на референс:  UCE795_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1248\n",
      "Очистка сборки на референс:  UCE692_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1067\n",
      "Очистка сборки на референс:  UCE31_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1047\n",
      "Очистка сборки на референс:  UCE855_Claster_3_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 701\n",
      "Очистка сборки на референс:  UCE980_Claster_3_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 192\n",
      "Очистка сборки на референс:  UCE103_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 504\n",
      "Очистка сборки на референс:  UCE21_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1203\n",
      "Очистка сборки на референс:  UCE855_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 481\n",
      "Очистка сборки на референс:  UCE418_Claster_0_Contig1\n",
      "Число плохих ридов 47 , Число хороших ридов 1692\n",
      "Очистка сборки на референс:  UCE467_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 2\n",
      "Очистка сборки на референс:  UCE1318_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1551\n",
      "Очистка сборки на референс:  UCE1001_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1541\n",
      "Очистка сборки на референс:  UCE1113_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 554\n",
      "Очистка сборки на референс:  UCE541_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 2335\n",
      "Очистка сборки на референс:  UCE526_Claster_1_Contig2\n",
      "Число плохих ридов 21 , Число хороших ридов 801\n",
      "Очистка сборки на референс:  UCE1326_Claster_0_Contig1\n",
      "Число плохих ридов 7 , Число хороших ридов 696\n",
      "Очистка сборки на референс:  UCE407_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 349\n",
      "Очистка сборки на референс:  UCE805_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1272\n",
      "Очистка сборки на референс:  UCE394_Claster_1_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 367\n",
      "Очистка сборки на референс:  UCE1305_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 447\n",
      "Очистка сборки на референс:  UCE697_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1256\n",
      "Очистка сборки на референс:  UCE514_Claster_0_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 515\n",
      "Очистка сборки на референс:  UCE932_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 292\n",
      "Очистка сборки на референс:  UCE699_Claster_0_Contig1\n",
      "Число плохих ридов 28 , Число хороших ридов 1698\n",
      "Очистка сборки на референс:  UCE1260_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 55\n",
      "Очистка сборки на референс:  UCE203_Claster_2_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 47\n",
      "Очистка сборки на референс:  UCE1270_Claster_1_Contig1\n",
      "Число плохих ридов 41 , Число хороших ридов 293\n",
      "Очистка сборки на референс:  UCE527_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1873\n",
      "Очистка сборки на референс:  UCE249_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1003\n",
      "Очистка сборки на референс:  UCE1204_Claster_0_Contig1\n",
      "Число плохих ридов 16 , Число хороших ридов 341\n",
      "Очистка сборки на референс:  UCE1133_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 545\n",
      "Очистка сборки на референс:  UCE196_Claster_0_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 622\n",
      "Очистка сборки на референс:  UCE639_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 304\n",
      "Очистка сборки на референс:  UCE1007_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1278\n",
      "Очистка сборки на референс:  UCE556_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 602\n",
      "Очистка сборки на референс:  UCE723_Claster_1_Contig1\n",
      "Число плохих ридов 11 , Число хороших ридов 188\n",
      "Очистка сборки на референс:  UCE408_Claster_0_Contig1\n",
      "Число плохих ридов 83 , Число хороших ридов 1456\n",
      "Очистка сборки на референс:  UCE624_Claster_0_Contig2\n",
      "Число плохих ридов 0 , Число хороших ридов 853\n",
      "Очистка сборки на референс:  UCE411_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 3155\n",
      "Очистка сборки на референс:  UCE498_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 339\n",
      "Очистка сборки на референс:  UCE808_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1487\n",
      "Очистка сборки на референс:  UCE251_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 1873\n",
      "Очистка сборки на референс:  UCE1282_Claster_0_Contig1\n",
      "Число плохих ридов 0 , Число хороших ридов 2456\n",
      "Очистка сборки на референс:  UCE118_Claster_0_Contig1\n",
      "Число плохих ридов 138 , Число хороших ридов 1618\n"
     ]
    }
   ],
   "source": [
    "curpath = os.path.abspath(os.path.curdir) # зафиксируем папку    \n",
    "files_sam_list = [x for x in os.listdir(curpath) if x.startswith(\"cart_\")] # endswith - кончается на (можно так сделать для начала)\n",
    "\n",
    "for sam_file in files_sam_list:\n",
    "\n",
    "    print(\"Идет обработка файла: \", sam_file)\n",
    "    data = pd.read_csv(sam_file, sep = '\\t',header=None, usecols=[0,3,9,5,1,2], index_col = False)\n",
    "    data.columns = ['Название рида','Flag','Ref','Начало рида', 'CIGAR','Рид']\n",
    "    data = data.loc[data['Flag'] != 2048] # чистка по флагам\n",
    "    data = data.loc[data['Flag'] != 2064]\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = SAM(data['Название рида'], data['Ref'], data['Начало рида'], data['CIGAR'], data['Рид'])\n",
    "    refs_in_sam = set(data.refs) # в sam файле смотрим сколько всего референсов.\n",
    "    print(\"Всего референсов:\",len(refs_in_sam))\n",
    "    for i, ref in enumerate(refs_in_sam): # открываем один из референсов: (весь алгоритм был расчитан на такую сборку)\n",
    "        reads = [] # в списке будут лежать риды для этого конкретного референса\n",
    "        Names = []\n",
    "        refs = Ref(ref)\n",
    "        #print('номер референса - ', i, \"Имя рефа\", ref)\n",
    "        for i in range(len(data.refs)):\n",
    "            if data.refs[i].encode() == ref.encode():\n",
    "                reads.append(READ(data.names.iloc[i], data.start.iloc[i], data.cigar.iloc[i], data.read.iloc[i]).ReadySeq())\n",
    "                Names.append(data.names.iloc[i])\n",
    "        print('Очистка сборки на референс: ', ref)\n",
    "        # зададим выравниевание отдельным объектом\n",
    "        align = ALIGN(refs, reads, data.names, data.cigar)\n",
    "        bad_reads = align.Cleaning(align.ReadWithChanges(align.AllChanges()), align.AllChanges(), align.RefCover())   \n",
    "        good_reads = []\n",
    "        for read in Names:\n",
    "            if read not in bad_reads:\n",
    "                good_reads.append(read + '\\t')\n",
    "        print(\"Число плохих ридов\",len(bad_reads), \", Число хороших ридов\", len(good_reads))\n",
    "        with open(\"Clear_{0:s}\".format(sam_file), 'a') as output:\n",
    "            with open(sam_file, \"r\") as file:\n",
    "                for lines in file:\n",
    "                    for read in good_reads:\n",
    "                        if read in lines:\n",
    "                            if ref in lines:\n",
    "                                #print(read, lines)\n",
    "                                output.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41610c1-8cd1-4756-8687-bd02dd964b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
